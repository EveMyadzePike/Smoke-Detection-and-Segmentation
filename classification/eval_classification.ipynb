{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('/path/to/classification')\n",
    "from model_classification import *\n",
    "from data_classification import create_dataset\n",
    "\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Clipping.*\")\n",
    "\n",
    "# Set the custom user-defined save path\n",
    "save_path = '/path/to/classification/plotImageFin/'\n",
    "\n",
    "\n",
    "# load data\n",
    "batch_size = 1 # 1 to create diagnostic images, any value otherwise\n",
    "testdata = create_dataset(datadir='/path/to/val')\n",
    "all_dl = DataLoader(testdata, batch_size=batch_size, shuffle=True)\n",
    "progress = tqdm(enumerate(all_dl), total=len(all_dl))\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(torch.load('/path/to/classification/classification.model', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# implant hooks for resnet layers\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.relu.register_forward_hook(get_activation('conv1'))\n",
    "model.layer1.register_forward_hook(get_activation('layer1'))\n",
    "model.layer2.register_forward_hook(get_activation('layer2'))\n",
    "model.layer3.register_forward_hook(get_activation('layer3'))\n",
    "model.layer4.register_forward_hook(get_activation('layer4'))\n",
    "\n",
    "\n",
    "# List to store the images\n",
    "images = []\n",
    "# run through test data set\n",
    "true = 0\n",
    "false = 0\n",
    "for i, batch in progress:\n",
    "    x, y = batch['img'].float().to(device), batch['lbl'].float().to(device)\n",
    "\n",
    "    output = model(x)\n",
    "    prediction = 1 if output[0] > 0 else 0\n",
    "\n",
    "    if prediction == 1 and y[0] == 1:\n",
    "        res = 'true_pos'\n",
    "        true += 1\n",
    "    elif prediction == 0 and y[0] == 0:\n",
    "        res = 'true_neg'\n",
    "        true += 1\n",
    "    elif prediction == 0 and y[0] == 1:\n",
    "        res = 'false_neg'\n",
    "        false += 1\n",
    "    elif prediction == 1 and y[0] == 0:\n",
    "        res = 'false_pos'\n",
    "        false += 1\n",
    "\n",
    "    if batch_size == 1:\n",
    "        # Create plot\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(1, 3))\n",
    "\n",
    "        rgb_img = 0.2 + 1.5 * (np.dstack([x[0][3], x[0][2], x[0][1]]) - np.min([x[0][3].numpy(),x[0][2].numpy(),x[0][1].numpy()])) / (np.max([x[0][3].numpy(),x[0][2].numpy(),x[0][1].numpy()]) -np.min([x[0][3].numpy(),x[0][2].numpy(),x[0][1].numpy()]))\n",
    "        rgb_img = np.clip(rgb_img, 0.0, 1.0)  # Clip values outside [0, 1]\n",
    "        ax1.imshow(rgb_img, origin='upper')\n",
    "        ax1.set_title({'true_pos': 'True Positive','true_neg': 'True Negative','false_pos': 'False Positive','false_neg': 'False Negative'}[res],\n",
    "                      fontsize=8)\n",
    "        ax1.set_ylabel('RGB', fontsize=8)\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "\n",
    "        false_color_img = 0.2 + (np.dstack([x[0][0], x[0][9], x[0][10]]) - np.min([x[0][0].numpy(), x[0][9].numpy(), x[0][10].numpy()])) / (np.max([x[0][0].numpy(), x[0][9].numpy(), x[0][10].numpy()]) - np.min([x[0][0].numpy(), x[0][9].numpy(), x[0][10].numpy()]))\n",
    "        false_color_img = np.clip(false_color_img, 0.0, 1.0)  # Clip values outside [0, 1]\n",
    "        ax2.imshow(false_color_img, origin='upper')\n",
    "        ax2.set_ylabel('False Color', fontsize=8)\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "\n",
    "        # Layer2 activations plot\n",
    "        map_layer2 = ax3.imshow(activation['layer2'].sum(axis=(0, 1)),\n",
    "                                vmin=50, vmax=150)\n",
    "        ax3.set_ylabel('Layer2', fontsize=8)\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_yticks([])\n",
    "\n",
    "        f.subplots_adjust(0.18, 0.02, 0.85, 0.9, 0.05, 0.05)\n",
    "\n",
    "        # Construct the filename\n",
    "        filename = os.path.split(batch['imgfile'][0])[1].replace('.tif', '_eval.png').replace(':', '_')\n",
    "\n",
    "        # Set the complete save path including the filename\n",
    "        complete_path = os.path.join(save_path, filename)\n",
    "\n",
    "        # Save the image at the specified path\n",
    "        plt.savefig(complete_path, dpi=200)\n",
    "\n",
    "        # Append the image to the list\n",
    "        images.append(f)\n",
    "\n",
    "        # Display the image\n",
    "        plt.close()\n",
    "\n",
    "# Display all the images together\n",
    "for image in images:\n",
    "    image.show()\n",
    "print('test set accuracy:', true / (true + false))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
