{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import Polygon\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(3)\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokePlumeSegmentationDataset():\n",
    "    \"\"\"SmokePlumeSegmentation dataset class.\"\"\"\n",
    "    def __init__(self,\n",
    "                 datadir='/path/to/images', seglabeldir='/path/to/segmentation_labels', mult=1,\n",
    "                 transform=None):\n",
    "       \n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "\n",
    "        # list of image files, labels (positive or negative), segmentation\n",
    "        # label vector edge coordinates\n",
    "        self.imgfiles = []\n",
    "        self.labels = []\n",
    "        self.seglabels = []\n",
    "\n",
    "        # list of indices of positive and negative images\n",
    "        self.positive_indices = []\n",
    "        self.negative_indices = []\n",
    "\n",
    "        # read in segmentation label files\n",
    "        seglabels = []\n",
    "        segfile_lookup = {}\n",
    "        for i, seglabelfile in enumerate(os.listdir(seglabeldir)):\n",
    "            segdata = json.load(open(os.path.join(seglabeldir, seglabelfile), 'r'))\n",
    "            seglabels.append(segdata)\n",
    "            my_img = segdata['data']['image']\n",
    "            timestamp = \"-\".join(my_img.split('-')[1:]).replace('.png', '.tif')\n",
    "            timestamp_with_underscores = timestamp.replace(':', '_')\n",
    "            segfile_lookup[timestamp_with_underscores] = i\n",
    "\n",
    "        # read in image file names for positive images\n",
    "        idx = 0\n",
    "        for root, dirs, files in os.walk(datadir):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.tif'):\n",
    "                    continue\n",
    "                if filename not in segfile_lookup.keys():\n",
    "                    continue\n",
    "                polygons = []\n",
    "                for completions in seglabels[segfile_lookup[filename]][\n",
    "                    'completions']:\n",
    "                    for result in completions['result']:\n",
    "                        polygons.append(\n",
    "                            np.array(result['value']['points'] +\n",
    "                                     [result['value']['points'][0]]) * 1.2)\n",
    "                        # factor of 1.2 necessary to scale edge coordinates\n",
    "                        # appropriately\n",
    "                if 'positive' in root and polygons != []:\n",
    "                    self.labels.append(True)\n",
    "                    self.positive_indices.append(idx)\n",
    "                    self.imgfiles.append(os.path.join(root, filename))\n",
    "                    self.seglabels.append(polygons)\n",
    "                    idx += 1\n",
    "                   \n",
    "\n",
    "        # add as many negative example images\n",
    "        for root, dirs, files in os.walk(datadir):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.tif'):\n",
    "                    continue\n",
    "                if idx >= len(self.positive_indices)*2:\n",
    "                    break\n",
    "                if 'negative' in root:\n",
    "                    self.labels.append(False)\n",
    "                    self.negative_indices.append(idx)\n",
    "                    self.imgfiles.append(os.path.join(root, filename))\n",
    "                    self.seglabels.append([])\n",
    "                    idx += 1\n",
    "\n",
    "        # turn lists into arrays\n",
    "        self.imgfiles = np.array(self.imgfiles)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.positive_indices = np.array(self.positive_indices)\n",
    "        self.negative_indices = np.array(self.negative_indices)\n",
    "\n",
    "        # increase data set size by factor `mult`\n",
    "        if mult > 1:\n",
    "            self.imgfiles = np.array([*self.imgfiles] * mult)\n",
    "            self.labels = np.array([*self.labels] * mult)\n",
    "            self.positive_indices = np.array([*self.positive_indices] * mult)\n",
    "            self.negative_indices = np.array([*self.negative_indices] * mult)\n",
    "            self.seglabels = self.seglabels * mult\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns length of data set.\"\"\"\n",
    "        return len(self.imgfiles)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Read in image data, preprocess, build segmentation mask, and apply\n",
    "        transformations.\"\"\"\n",
    "\n",
    "        # read in image data\n",
    "        imgfile = rio.open(self.imgfiles[idx])\n",
    "        imgdata = np.array([imgfile.read(i) for i in\n",
    "                            [1,2,3,4,5,6,7,8,9,10,12,13]])\n",
    "        # skip band 11 (Sentinel-2 Band 10, Cirrus) as it does not contain\n",
    "        # useful information in the case of Level-2A data products\n",
    "\n",
    "        # force image shape to be 120 x 120 pixels\n",
    "        if imgdata.shape[1] != 120:\n",
    "            newimgdata = np.empty((12, 120, imgdata.shape[2]))\n",
    "            newimgdata[:, :imgdata.shape[1], :] = imgdata[:,\n",
    "                                                  :imgdata.shape[1], :]\n",
    "            newimgdata[:, imgdata.shape[1]:, :] = imgdata[:,\n",
    "                                                  imgdata.shape[1]-1:, :]\n",
    "            imgdata = newimgdata\n",
    "        if imgdata.shape[2] != 120:\n",
    "            newimgdata = np.empty((12, 120, 120))\n",
    "            newimgdata[:, :, :imgdata.shape[2]] = imgdata[:,\n",
    "                                                  :, :imgdata.shape[2]]\n",
    "            newimgdata[:, :, imgdata.shape[2]:] = imgdata[:,\n",
    "                                                  :, imgdata.shape[2]-1:]\n",
    "            imgdata = newimgdata\n",
    "\n",
    "        # rasterize segmentation polygons\n",
    "        fptdata = np.zeros(imgdata.shape[1:], dtype=np.uint8)\n",
    "        polygons = self.seglabels[idx]\n",
    "        shapes = []\n",
    "        if len(polygons) > 0:\n",
    "            for pol in polygons:\n",
    "                try:\n",
    "                    pol = Polygon(pol)\n",
    "                    shapes.append(pol)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            fptdata = rasterize(((g, 1) for g in shapes),\n",
    "                                out_shape=fptdata.shape,\n",
    "                                all_touched=True)\n",
    "\n",
    "        sample = {'idx': idx,\n",
    "                  'img': imgdata,\n",
    "                  'fpt': fptdata,\n",
    "                  'imgfile': self.imgfiles[idx]}\n",
    "\n",
    "        # apply transformations\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def display(self, idx):\n",
    "        sample = self[idx]\n",
    "        imgdata = sample['img']\n",
    "        fptdata = sample['fpt']\n",
    "        offset = 0.3\n",
    "        scaling = 1.0\n",
    "\n",
    "\n",
    "        # scale image data\n",
    "        imgdata = offset+scaling*(\n",
    "            np.dstack([imgdata[3], imgdata[2], imgdata[1]])-\n",
    "            np.min([imgdata[3], imgdata[2], imgdata[1]]))/ \\\n",
    "                (np.max([imgdata[3], imgdata[2], imgdata[1]])-\n",
    "                 np.min([imgdata[3], imgdata[2], imgdata[1]]))\n",
    "\n",
    "        \n",
    "        # Normalize the input arrays\n",
    "        imgdata_normalized = imgdata / 255.0  # Assuming imgdata is an integer array\n",
    "        fptdata_normalized = fptdata / 255.0  # Assuming fptdata is an integer array\n",
    "        \n",
    "        f, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "        # axs[0].imshow(imgdata)\n",
    "        clipped_img = np.clip(imgdata, 0.0, 1.0)  # Clip values outside [0, 1]\n",
    "        axs[0].imshow(clipped_img, origin='upper')\n",
    "        axs[0].set_title('Image Data')\n",
    "        axs[0].set_xlim(0, imgdata.shape[1])\n",
    "\n",
    "        axs[1].imshow(fptdata,cmap='nipy_spectral')\n",
    "        axs[1].set_title('Segmentation Label Outlines')\n",
    "\n",
    "        return f  \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        out = {'idx': sample['idx'],\n",
    "               'img': torch.from_numpy(sample['img'].copy()),\n",
    "               'fpt': torch.from_numpy(sample['fpt'].copy()),\n",
    "               'imgfile': sample['imgfile']}\n",
    "\n",
    "        return out\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self):\n",
    "        self.channel_means = np.array(\n",
    "            [809.2, 900.5, 1061.4, 1091.7, 1384.5, 1917.8,\n",
    "             2105.2, 2186.3, 2224.8, 2346.8, 1901.2, 1460.42])\n",
    "        self.channel_stds = np.array(\n",
    "            [441.8, 624.7, 640.8, 718.1, 669.1, 767.5,\n",
    "             843.3, 947.9, 882.4, 813.7, 716.9, 674.8])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['img'] = (sample['img']-self.channel_means.reshape(\n",
    "            sample['img'].shape[0], 1, 1))/self.channel_stds.reshape(\n",
    "            sample['img'].shape[0], 1, 1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class Randomize(object):\n",
    "    def __call__(self, sample):\n",
    "        imgdata = sample['img']\n",
    "        fptdata = sample['fpt']\n",
    "\n",
    "        # mirror horizontally\n",
    "        mirror = np.random.randint(0, 2)\n",
    "        if mirror:\n",
    "            imgdata = np.flip(imgdata, 2)\n",
    "            fptdata = np.flip(fptdata, 1)\n",
    "        # flip vertically\n",
    "        flip = np.random.randint(0, 2)\n",
    "        if flip:\n",
    "            imgdata = np.flip(imgdata, 1)\n",
    "            fptdata = np.flip(fptdata, 0)\n",
    "        # rotate by [0,1,2,3]*90 deg\n",
    "        rot = np.random.randint(0, 4)\n",
    "        imgdata = np.rot90(imgdata, rot, axes=(1,2))\n",
    "        fptdata = np.rot90(fptdata, rot, axes=(0,1))\n",
    "\n",
    "        return {'idx': sample['idx'],\n",
    "                'img': imgdata.copy(),\n",
    "                'fpt': fptdata.copy(),\n",
    "                'imgfile': sample['imgfile']}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Randomly crop 90x90 pixel image (from 120x120).\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imgdata = sample['img']\n",
    "\n",
    "        x, y = np.random.randint(0, 30, 2)\n",
    "\n",
    "        return {'idx': sample['idx'],\n",
    "                'img': imgdata.copy()[:, y:y+90, x:x+90],\n",
    "                'fpt': sample['fpt'].copy()[y:y+90, x:x+90],\n",
    "                'imgfile': sample['imgfile']}\n",
    "\n",
    "\n",
    "def create_dataset(*args, apply_transforms=True, **kwargs):\n",
    "    if apply_transforms:\n",
    "        data_transforms = transforms.Compose([\n",
    "            Normalize(),\n",
    "            Randomize(),\n",
    "            RandomCrop(),\n",
    "            ToTensor()\n",
    "           ])\n",
    "    else:\n",
    "        data_transforms = None\n",
    "\n",
    "    data = SmokePlumeSegmentationDataset(*args, **kwargs,\n",
    "                                         transform=data_transforms)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the image and segmentation label directories\n",
    "datadir = '/path/to/images'\n",
    "seglabeldir = '/path/to/segmentation_labels'\n",
    "\n",
    "# Create the dataset\n",
    "dataset = SmokePlumeSegmentationDataset(datadir=datadir, seglabeldir=seglabeldir, mult=3, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.__len__()  # size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.display(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
