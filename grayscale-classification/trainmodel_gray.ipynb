{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "\n",
    "import model_gray\n",
    "import gray_dataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tensor):\n",
    "    tensor = tensor.to(torch.float32)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def train_model(model, epochs, opt, loss, batch_size):\n",
    "\n",
    "    # create dataset\n",
    "    data_train = gray_dataClass.create_dataset(datadir='path/to/gray_images', mult=1)\n",
    "\n",
    "    data_val = gray_dataClass.create_dataset(datadir='path/to/gray_images', mult=1)\n",
    "\n",
    "    # draw random subsamples\n",
    "    train_sampler = RandomSampler(data_train, replacement=True, num_samples=int(2*len(data_train)/3))\n",
    "    val_sampler = RandomSampler(data_val, replacement=True, num_samples=int(2*len(data_val)/3))\n",
    "\n",
    "    # initialize data loaders\n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size, num_workers=2, pin_memory=True, sampler=train_sampler)\n",
    "    val_dl = DataLoader(data_val, batch_size=batch_size, num_workers=2, pin_memory=True, sampler=val_sampler)\n",
    "\n",
    "    # start training process\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss_total, train_acc_total = 0, 0\n",
    "        progress = tqdm(enumerate(train_dl), desc=\"Train Loss: \", total=len(train_dl))\n",
    "        for i, batch in progress:\n",
    "            x = transform(batch['img']).to(device)  # Apply the transform to input data\n",
    "            y = batch['lbl'].float().to(device)\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            # derive binary output\n",
    "            output_binary = np.zeros(output.shape)\n",
    "            output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "\n",
    "            # derive accuracy score\n",
    "            acc = accuracy_score(y.cpu().detach().numpy(), output_binary)\n",
    "            train_acc_total += acc\n",
    "\n",
    "            # calculate loss\n",
    "            loss_epoch = loss(output, y.reshape(-1, 1))\n",
    "            train_loss_total += loss_epoch.item()\n",
    "            progress.set_description(\"Train Loss: {:.4f}\".format(train_loss_total/(i+1)))\n",
    "\n",
    "            # learning\n",
    "            opt.zero_grad()\n",
    "            loss_epoch.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # logging\n",
    "        writer.add_scalar(\"training loss\", train_loss_total/(i+1), epoch)\n",
    "        writer.add_scalar(\"training acc\", train_acc_total/(i+1), epoch)\n",
    "        writer.add_scalar('learning_rate', opt.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # evaluation based on validation sample\n",
    "        model.eval()\n",
    "        val_loss_total, val_acc_total = 0, 0\n",
    "        progress = tqdm(enumerate(val_dl), desc=\"val Loss: \", total=len(val_dl))\n",
    "        for j, batch in progress:\n",
    "            x, y = batch['img'].float().to(device), batch['lbl'].float().to(device)\n",
    "\n",
    "            output = model(x)\n",
    "\n",
    "            # calculate loss\n",
    "            loss_epoch = loss(output, y.reshape(-1, 1))\n",
    "            val_loss_total += loss_epoch.item()\n",
    "            progress.set_description(\"val Loss: {:.4f}\".format(val_loss_total/(j+1)))\n",
    "\n",
    "            # derive binary output\n",
    "            output_binary = np.zeros(output.shape)\n",
    "            output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "\n",
    "            # derive accuracy score\n",
    "            acc = accuracy_score(y.cpu().detach().numpy(), output_binary)\n",
    "            val_acc_total += acc\n",
    "\n",
    "        # logging\n",
    "        writer.add_scalar(\"val loss\", val_loss_total/(j+1), epoch)\n",
    "        writer.add_scalar(\"val accuracy\", val_acc_total/(j+1), epoch)\n",
    "\n",
    "        # screen output\n",
    "        print((\"Epoch {:d}: train loss={:.3f}, val loss={:.3f}, train acc={:.3f}, val acc={:.3f}\").format(epoch+1, train_loss_total/(i+1), val_loss_total/(j+1), train_acc_total/(i+1), val_acc_total/(j+1)))\n",
    "\n",
    "        writer.flush()\n",
    "        scheduler.step(epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Save the trained model\n",
    "        save_path = os.path.join(save_dir, 'grayclassification.model')\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Trained model saved at {save_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Modify the argument parsing code to avoid conflicts with Jupyter kernel arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-ep', type=int, default=5, help='Number of epochs')\n",
    "parser.add_argument('-bs', type=int, nargs='?', default=32, help='Batch size')\n",
    "parser.add_argument('-lr', type=float, nargs='?', default=0.3, help='Learning rate')\n",
    "parser.add_argument('-mo', type=float, nargs='?', default=0.7, help='Momentum')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Specify the directory to save the trained model\n",
    "save_dir = 'path/to/save/'\n",
    "\n",
    "# initialize tensorboard writer\n",
    "writer = SummaryWriter('runs/'+\"ep{:0d}_lr{:.0e}_bs{:03d}_mo{:.1f}/\".format(args.ep, args.lr, args.bs, args.mo))\n",
    "\n",
    "# initialize loss, optimizer, and scheduler\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "opt = optim.SGD(model.parameters(), lr=args.lr, momentum=args.mo)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', factor=0.5, threshold=1e-4, min_lr=1e-6)\n",
    "\n",
    "# run model training\n",
    "train_model(model, args.ep, opt, loss, args.bs)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
